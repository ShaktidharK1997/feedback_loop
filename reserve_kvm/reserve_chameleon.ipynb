{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reserve and configure resources on KVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run this experiment, you will:\n",
    "\n",
    "-   define the specific configuration of resources you need.\n",
    "-   “instantiate” an experiment with your reserved resources.\n",
    "-   wait for your resources to be configured.\n",
    "-   log in to resources to carry out the experiment.\n",
    "\n",
    "This exercise will guide you through those steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openstack, chi, chi.ssh, chi.network, chi.server, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we configure the Chameleon Python client.\n",
    "\n",
    "For this experiment, we’re going to use the KVM@TACC site, which we indicate below.\n",
    "\n",
    "We also need to specify the name of the Chameleon “project” that this experiment is part of. The project name will have the format “CHI-XXXXXX”, where the last part is a 6-digit number, and you can find it on your [user dashboard](https://chameleoncloud.org/user/dashboard/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, replace the project ID with your own project ID, then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi.use_site(\"KVM@TACC\")\n",
    "PROJECT_NAME = \"CHI-XXXXXX\"\n",
    "chi.set(\"project_name\", PROJECT_NAME)\n",
    "\n",
    "# configure openstacksdk for actions unsupported by python-chi\n",
    "os_conn = chi.clients.connection()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define configuration for this experiment (3 VMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this specific experiment, we will need 1 virtual machines connected to a common network. Each of the virtual machines will be of the `m1.large` type, with 4 VCPUs, 8 GB memory, 40 GB disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getenv('USER')\n",
    "\n",
    "node_conf = [\n",
    " {'name': \"node-0\",  'flavor': 'm1.medium', 'image': 'CC-Ubuntu22.04', 'packages': [\"virtualenv\"]}, \n",
    "]\n",
    "net_conf = [\n",
    " {\"name\": \"net0\", \"subnet\": \"192.168.1.0/24\", \"nodes\": [{\"name\": \"node-0\",   \"addr\": \"192.168.1.10\"}]},\n",
    "]\n",
    "route_conf = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure resources\n",
    "\n",
    "Now, we will prepare the VMs and network links that our experiment requires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will prepare a “public” network that we will use for SSH access to our VMs -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_net = os_conn.network.create_network(name=\"public_net_\" + username)\n",
    "public_net_id = public_net.get(\"id\")\n",
    "public_subnet = os_conn.network.create_subnet(\n",
    "    name=\"public_subnet_\" + username,\n",
    "    network_id=public_net.get(\"id\"),\n",
    "    ip_version='4',\n",
    "    cidr=\"192.168.10.0/24\",\n",
    "    gateway_ip=\"192.168.10.1\",\n",
    "    is_dhcp_enabled = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare the “experiment” networks -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = []\n",
    "net_ids = []\n",
    "subnets = []\n",
    "for n in net_conf:\n",
    "    exp_net = os_conn.network.create_network(name=\"exp_\" + n['name']  + '_' + username)\n",
    "    exp_net_id = exp_net.get(\"id\")\n",
    "    os_conn.network.update_network(exp_net, is_port_security_enabled=False)\n",
    "    exp_subnet = os_conn.network.create_subnet(\n",
    "        name=\"exp_subnet_\" + n['name']  + '_' + username,\n",
    "        network_id=exp_net.get(\"id\"),\n",
    "        ip_version='4',\n",
    "        cidr=n['subnet'],\n",
    "        gateway_ip=None,\n",
    "        is_dhcp_enabled = True\n",
    "    )\n",
    "    nets.append(exp_net)\n",
    "    net_ids.append(exp_net_id)\n",
    "    subnets.append(exp_subnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the VMs -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servers = []\n",
    "server_ids = []\n",
    "for i, n in enumerate(node_conf, start=10):\n",
    "    image_uuid = os_conn.image.find_image(n['image']).id\n",
    "    flavor_uuid = os_conn.compute.find_flavor(n['flavor']).id\n",
    "    # find out details of exp interface(s)\n",
    "    nics = [{'net-id': chi.network.get_network_id( \"exp_\" + net['name']  + '_' + username ), 'v4-fixed-ip': node['addr']} for net in net_conf for node in net['nodes'] if node['name']==n['name']]\n",
    "    # also include a public network interface\n",
    "    nics.insert(0, {\"net-id\": public_net_id, \"v4-fixed-ip\":\"192.168.10.\" + str(i)})\n",
    "    server = chi.server.create_server(\n",
    "        server_name=n['name'] + \"_\" + username,\n",
    "        image_id=image_uuid,\n",
    "        flavor_id=flavor_uuid,\n",
    "        nics=nics\n",
    "    )\n",
    "    servers.append(server)\n",
    "    server_ids.append(chi.server.get_server(n['name'] + \"_\" + username).id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wait for all servers to come up before we proceed -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for server_id in server_ids:\n",
    "    chi.server.wait_for_active(server_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will set up SSH access to the VMs.\n",
    "\n",
    "First, we will make sure the “public” network is connected to the Internet. Then, we will configure it to permit SSH access on port 22 for each port connected to this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect them to the Internet on the \"public\" network (e.g. for software installation)\n",
    "router = chi.network.create_router('inet_router_' + username, gw_network_name='public')\n",
    "chi.network.add_subnet_to_router(router.get(\"id\"), public_subnet.get(\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare SSH access on the server\n",
    "# WARNING: this relies on undocumented behavior of associate_floating_ip \n",
    "# that it associates the IP with the first port on the server\n",
    "server_ips = []\n",
    "for i, n in enumerate(node_conf):\n",
    "    ip = chi.server.associate_floating_ip(server_ids[i])\n",
    "    server_ips.append(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os_conn.get_security_group(\"Allow SSH\"):\n",
    "    os_conn.create_security_group(\"Allow SSH\", \"Enable SSH traffic on TCP port 22\")\n",
    "    os_conn.create_security_group_rule(\"Allow SSH\", port_range_min=22, port_range_max=22, protocol='tcp', remote_ip_prefix='0.0.0.0/0')\n",
    "\n",
    "security_group_id = os_conn.get_security_group(\"Allow SSH\").id\n",
    "for port in chi.network.list_ports(): \n",
    "    if port['port_security_enabled'] and port['network_id']==public_net.get(\"id\"):\n",
    "        os_conn.network.update_port(port['id'], security_groups=[security_group_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ip in server_ips:\n",
    "    chi.server.wait_for_tcp(ip, port=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell may raise an error if some of your nodes are still getting set up! If that happens, wait a few minutes and try again. (And then a few minutes more, and try again, if it still raises an error.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_remote = chi.ssh.Remote(server_ips[0])\n",
    "physical_ips = [n['addr'] for n in net_conf[0]['nodes']]\n",
    "server_remotes = [chi.ssh.Remote(physical_ip, gateway=primary_remote) for physical_ip in physical_ips]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to configure our resources, including software package installation and network configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for i, n in enumerate(node_conf):\n",
    "    remote = server_remotes[i]\n",
    "    # enable forwarding\n",
    "    remote.run(f\"sudo sysctl -w net.ipv4.ip_forward=1\") \n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=192.168.0.0/16 --permanent\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=172.16.0.0/12 --permanent\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=10.0.0.0/8 --permanent\")\n",
    "    remote.run(f\"sudo firewall-cmd --zone=trusted --add-source=127.0.0.0/8 --permanent\")\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, n in enumerate(node_conf):\n",
    "    # install packages\n",
    "    if len(n['packages']):\n",
    "            remote = server_remotes[i]\n",
    "            remote.run(f\"sudo apt update; sudo apt -y install \" + \" \".join(n['packages'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a \"hosts\" file that has names and addresses of every node\n",
    "hosts_txt = [ \"%s\\t%s\" % ( n['addr'], n['name'] ) for net in net_conf  for n in net['nodes'] if type(n) is dict and n['addr']]\n",
    "for remote in server_remotes:\n",
    "    for h in hosts_txt:\n",
    "        remote.run(\"echo %s | sudo tee -a /etc/hosts > /dev/null\" % h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need to enable incoming traffic on the HTTP port\n",
    "if not os_conn.get_security_group(\"Allow HTTP 32000\"):\n",
    "    os_conn.create_security_group(\"Allow HTTP 32000\", \"Enable HTTP traffic on TCP port 32000\")\n",
    "    os_conn.create_security_group_rule(\"Allow HTTP 32000\", port_range_min=32000, port_range_max=32000, protocol='tcp', remote_ip_prefix='0.0.0.0/0')\n",
    "\n",
    "# add existing security group\n",
    "security_group_id = os_conn.get_security_group(\"Allow HTTP 32000\").id\n",
    "for port in chi.network.list_ports(): \n",
    "    if port['port_security_enabled'] and port['network_id']==public_net.get(\"id\"):\n",
    "        pri_security_groups = port['security_groups']\n",
    "        pri_security_groups.append(security_group_id)\n",
    "        os_conn.network.update_port(port['id'], security_groups=pri_security_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need to enable incoming traffic on the HTTP port\n",
    "if not os_conn.get_security_group(\"Allow HTTP 8088\"):\n",
    "    os_conn.create_security_group(\"Allow HTTP 8088\", \"Enable HTTP traffic on TCP port 8088\")\n",
    "    os_conn.create_security_group_rule(\"Allow HTTP 8088\", port_range_min=8088, port_range_max=8088, protocol='tcp', remote_ip_prefix='0.0.0.0/0')\n",
    "\n",
    "# add existing security group\n",
    "security_group_id = os_conn.get_security_group(\"Allow HTTP 8088\").id\n",
    "for port in chi.network.list_ports(): \n",
    "    if port['port_security_enabled'] and port['network_id']==public_net.get(\"id\"):\n",
    "        pri_security_groups = port['security_groups']\n",
    "        pri_security_groups.append(security_group_id)\n",
    "        os_conn.network.update_port(port['id'], security_groups=pri_security_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the network topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will draw the network topology, for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [ (n['name'], {'color': 'pink'}) for n in net_conf ] + [(n['name'], {'color': 'lightblue'}) for n in node_conf ]\n",
    "edges = [(net['name'], node['name'], \n",
    "          {'label': node['addr'] + '/' + net['subnet'].split(\"/\")[1] }) if node['addr'] else (net['name'], node['name']) for net in net_conf for node in net['nodes'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(len(nodes),len(nodes)))\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, node_shape='s',  \n",
    "        node_color=[n[1]['color'] for n in nodes], \n",
    "        node_size=[len(n[0])*400 for n in nodes],  \n",
    "        with_labels=True);\n",
    "nx.draw_networkx_edge_labels(G,pos,\n",
    "                             edge_labels=nx.get_edge_attributes(G,'label'),\n",
    "                             font_color='gray',  font_size=8, rotate=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = chi.ssh.Remote(server_ips[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run(\"sudo apt-get update\")\n",
    "remote.run(\"sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run(\"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\")\n",
    "remote.run('echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run(\"sudo apt-get update\")\n",
    "remote.run(\"sudo apt-get install -y docker-ce docker-ce-cli containerd.io\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run('sudo groupadd -f docker; sudo usermod -aG docker $USER')\n",
    "remote.run(\"sudo chmod 666 /var/run/docker.sock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check configuration\n",
    "remote.run(\"docker run hello-world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote.run(\"sudo apt-get install -y python3 python3-pip\")\n",
    "remote.run(\"python3 -m pip config set global.break-system-packages true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install docker compose \n",
    "# Download the docker compose plugin\n",
    "remote.run(\"sudo curl -L https://github.com/docker/compose/releases/download/v2.24.5/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose\")\n",
    "\n",
    "# Make it executable\n",
    "remote.run(\"sudo chmod +x /usr/local/bin/docker-compose\")\n",
    "\n",
    "# Verify the installation\n",
    "remote.run(\"docker-compose --version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Feedback Loop\n",
    "\n",
    "We have talked about feedback loops. Let’s start by exploring a basic feedback mechanism where users directly provide feedback on food classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the gourmetgram repository with user_corrected branch \n",
    "remote.run(\"git clone -b user_corrected https://github.com/ShaktidharK1997/gourmetgram.git\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!NOTE : Once Docker-compose is set up, please take the env file that has been shared with you and copy it into the gourmetgram repository. This is important for the application to work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use docker to setup the Flask application\n",
    "remote.run(\"cd gourmetgram; docker-compose up -d --build\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore User Feedback System\n",
    "\n",
    "1.  Access the Web Interface:\n",
    "    -   Open your browser and navigate to: http://localhost:8000\n",
    "    -   You’ll see the Gourmet Gram interface for uploading and classifying food images\n",
    "2.  Test the Classification System:\n",
    "    -   Upload a food image using the interface\n",
    "    -   The system will display its prediction\n",
    "    -   You can either confirm the prediction is correct or select the correct class if it’s wrong\n",
    "3.  Explore the MinIO Storage:\n",
    "    -   Navigate to http://localhost:9001\n",
    "    -   Login with the credentials username: minioadmin, password: minioadmin\n",
    "    -   Explore the `production-images` bucket to see how images are organized by class\n",
    "    -   Check the `tracking bucket` to view the JSON files that track user corrections\n",
    "4.  Generate a Test Suite:\n",
    "    -   You can generate a test suite based on user corrections by running:\n",
    "\n",
    "    ``` bash\n",
    "    curl -X GET \"http://localhost:8000/generate_test_suite\"\n",
    "    ```\n",
    "\n",
    "    -   This will create a timestamped directory in the test-suites bucket containing corrected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to shut down the application\n",
    "remote.run(\"cd gourmetgram; docker-compose down -v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages of User Feedback\n",
    "\n",
    "However, this approach of taking the user’s feedback is not optimal for many reasons:\n",
    "\n",
    "-   Users come to Gourmet Gram seeking food classification, not to provide expert labels. There’s a high probability they’ll misclassify images, and retraining with this feedback would significantly degrade model performance.\n",
    "\n",
    "-   User feedback in production ML systems introduces subtle biases. For example, in our Gourmet Gram UI, food classes are listed in a fixed order while providing feedback. This creates an implicit bias where options at the top of the menu catch users’ attention first and are selected more frequently, regardless of correctness.\n",
    "\n",
    "-   This phenomenon, called “degenerate feedback loops” is widespread in recommendation systems. On Netflix, already-popular shows receive more prominent placement, leading to more views, which then reinforces their “popularity” in the algorithm. These loops don’t necessarily reflect quality or relevance to individual users, but rather amplify existing popularity patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human in the Loop Approach\n",
    "\n",
    "For this reason, companies use a Human in the Loop approach to improve their model performance. In this case, predictions which either have a low confidence or user disagrees with are sent to data annotators. These annotators have significant experience in the domain of the model and therefore can provide reliable labels for the tasks at hand. These high-quality labels are then used to retrain the model, leading to better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Human in the Loop System\n",
    "\n",
    "Lets try and setting up a Human in the Loop approach for Gourmetgram! For this, we are using `Label Studio` which is an open source data labeling platform.\n",
    "\n",
    "https://labelstud.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fetch and checkout to feedback_loop_integration branch\n",
    "remote.run(\"cd gourmetgram; git fetch origin feedback_loop_integration; git checkout feedback_loop_integration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets bring the minio and label-studio containers first\n",
    "remote.run(\"cd gourmetgram; docker-compose up -d minio label-studio\")\n",
    "\n",
    "# Wait 30 seconds for Label studio to get started ...\n",
    "remote.run('sleep(30)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets bring the flask application now\n",
    "remote.run(\"cd gourmetgram; docker-compose up flask-app --build\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Human in the Loop System\n",
    "\n",
    "1.  Access the Web Interface:\n",
    "    -   Open your browser and navigate to: http://localhost:8000\n",
    "    -   Upload food images for classification\n",
    "2.  Provide Feedback:\n",
    "    -   After seeing a prediction, you can give thumbs up (correct) or thumbs down (incorrect)\n",
    "    -   Notice that unlike the first system, you don’t directly provide the correct class\n",
    "    -   Images with low confidence or negative feedback are sent to Label Studio for expert review\n",
    "3.  Explore Label Studio (Annotation Interface):\n",
    "    -   Navigate to http://localhost:8080\n",
    "    -   Login with username: gourmetgramuser@gmail.com, password: gourmetgrampassword\n",
    "    -   Select the “Food Classification Review” project\n",
    "    -   Click on “Tasks” to see images waiting for expert review\n",
    "    -   For each task, select the correct food category and submit your annotation\n",
    "4.  Create random sampling tasks `bash     curl -X POST \"http://localhost:8000/sample_random_images\" -H \"Content-Type: application/json\" -d '{\"sample_count\": 5}'`\n",
    "5.  Process Expert Annotations:\n",
    "    -   After annotating some images in Label Studio, process these annotations:\n",
    "\n",
    "    ``` bash\n",
    "    curl -X POST \"http://localhost:8000/process_labels\"\n",
    "    ```\n",
    "\n",
    "    This will move images to their correct class directories\n",
    "6.  Create test suites:\n",
    "    -   After processing the labels, create test cases based on task type (random sampling, low confidence or user feedback)\n",
    "\n",
    "    ``` bash\n",
    "    curl -X GET http://localhost:8000/generate_test_suite?task_type=user_feedback\n",
    "    curl -X GET http://localhost:8000/generate_test_suite?task_type=low_confidence\n",
    "    curl -X GET http://localhost:8000/generate_test_suite?task_type=random_sampling\n",
    "    curl -X GET http://localhost:8000/generate_test_suite?task_type=all\n",
    "    ```\n",
    "7.  Explore MinIO contents:\n",
    "    -   Navigate to http://localhost:9001\n",
    "    -   Examine the different buckets to see how data is organized:\n",
    "        -   `production-images`: Contains all classified images\n",
    "        -   `tracking`: Contains tracking JSONs for different feedback sources\n",
    "        -   `target-bucket`: Where Label Studio exports annotations\n",
    "        -   `test-suites`: Contains organized test suites for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to shut down the application\n",
    "remote.run(\"cd gourmetgram; docker-compose down -v\")"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 }
}
